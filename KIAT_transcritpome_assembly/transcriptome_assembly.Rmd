---
title: "Transcritpome_assembly"
author: "Ruijuan Li"
date: "6/26/2017"
output: 
  html_document: 
    keep_md: yes
---

#### download data & trimming 
```{r}
# 1) download raw fastq data using wget 

# 2) check data quality using fastqc 

# 3) Trimm off low quality reads & adapter contamination 
# trimmomatic PE Sample_${sample}/${sample}_1.fq.gz Sample_${sample}/${sample}_2.fq.gz Sample_${sample}/${sample}_paired_1.fq.gz Sample_${sample}/${sample}_unpaired_1.fq.gz Sample_${sample}/${sample}_paired_2.fq.gz Sample_${sample}/${sample}_unpaired_2.fq.gz ILLUMINACLIP:Bradseq_adapter.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36

# 4) map high quality reads to reference genome using STAR
# 4.1) add "gene_id" colomn to gff3 file 
# run with modified gff3 file 
# STAR --runMode genomeGenerate --genomeDir star_genome/ --genomeFastaFiles Brassica_napus_v4.1.chromosomes.fa --sjdbGTFfile Brassica_napus.annotation_v5_modified_modified.gff3 --runThreadN 6 --sjdbGTFtagExonParentTranscript Parent --sjdbGTFfeatureExon CDS (screen -r 10070.ttys003.coloma) 

############# reference based ##################### 
# 4.2)  mapping 
# "STAR --genomeDir /Network/Servers/avalanche.plb.ucdavis.edu/Volumes/Mammoth/Users/ruijuanli/Reference/B.napus/star_genome --readFilesIn /Network/Servers/avalanche.plb.ucdavis.edu/Volumes/Mammoth/Users/ruijuanli/2016_summer/raw_data/Ae_Hu_2_1.fq /Network/Servers/avalanche.plb.ucdavis.edu/Volumes/Mammoth/Users/ruijuanli/2016_summer/raw_data/Ae_Hu_2_2.fq --outSAMtype BAM SortedByCoordinate --sjdbGTFfile /Network/Servers/avalanche.plb.ucdavis.edu/Volumes/Mammoth/Users/ruijuanli/Reference/B.napus/Brassica_napus.annotation_v5_modified_modified.gff3 --quantMode TranscriptomeSAM GeneCounts --twopassMode Basic â€“alignIntronMax 15000 --outFilterIntronMotifs RemoveNoncanonical --runThreadN 6 --sjdbGTFtagExonParentTranscript Parent --sjdbGTFfeatureExon CDS --outReadsUnmapped Fastx" 

# 5) assembly 
# 5.1) use IGV to decide library type 
# after visualize genome, bam file, and gff file, we decide our library type is fr-secondstrand 
# 5.2) assemble each library seperately using cufflinks 
# transcriptome assembly using original gff3 file
# cufflinks  -o /share/malooflab/Ruijuan/parent_assembly/${sample}/cufflink_output/ \
# 	   --junc-alpha 0.001 \
# 	   --label CUFF \
# 	   --max-bundle-length 3500000 \
# 	   --max-intron-length 300000 \
# 	   --max-mle-iterations 5000 \
# 	   --min-frags-per-transfrag 10 \
# 	   --min-intron-length 50 \
# 	   --min-isoform-fraction 0.1 \
# 	   --no-update-check \
# 	   --num-importance-samples 1000 \
# 	   --num-threads 20 \
# 	   --overhang-tolerance 8 \
# 	   --pre-mrna-fraction 0.15 \
# 	   --small-anchor-fraction 0.09 \
# 	   --trim-3-avgcov-thresh 10 \
# 	   --trim-3-dropoff-frac 0.1 \
# 	   --library-type fr-secondstrand \
# 	   -g /share/malooflab/Ruijuan/reference/Brassica_napus.annotation_v5.gff3 \
# 	   -b /home/ruijuanli/2017_winter/assembly/Brassica_napus_v4.1.chromosomes.fa \
# 	    /share/malooflab/Ruijuan/parent_assembly/${sample}/Aligned.sortedByCoord.out.bam

# 6) merge seperate assembly into one using cuffmerge 
# cuffmerge 
# https://github.com/leejimmy93/KIAT_whitney/blob/master/parent_RNA_transcriptome/run_cuffmerge_Ae.sh 

# https://github.com/leejimmy93/KIAT_whitney/blob/master/parent_RNA_transcriptome/run_cuffmerge_Ol.sh

# 7) compare to current annotation for the reference genome  
# cuffcompare 

# https://github.com/leejimmy93/KIAT_whitney/blob/master/parent_RNA_transcriptome/run_cuffcompare_Ae.sh
# https://github.com/leejimmy93/KIAT_whitney/blob/master/parent_RNA_transcriptome/run_cuffcompare_Ol.sh 

# 8) remove redundant isoforms from novel transcripts using CAP3 
# https://github.com/leejimmy93/KIAT_whitney/blob/master/parent_RNA_transcriptome/run_cap3.sh

# 9) predict ORF from non-redundant transcript dataset using transdecoder 
# TransDecoder.LongOrfs -t Ae.u.fa 
# TransDecoder.LongOrfs -t Ol.u.fa 

# 10) blastp against nr protein database to get an idea of what genes they are 
# blastp -query longest_orfs.pep  -db /Network/Servers/avalanche.plb.ucdavis.edu/Volumes/Mammoth/Users/ruijuanli/Reference/NCBI/nr/nr  -max_target_seqs 1 -outfmt 6 -evalue 1e-6 -num_threads 6 -out ${i}_nr.out 

# 11) the number of novel genes which can be annotated 
# cat longest_orfs.pep | grep ">" | sed 's/:/\t/g' | awk '{print $2}' | sort | uniq | wc -l
# for Da-Ae 2311; for Da-Ol-1 2427 

# extract sequences that need go for annotation 
# cat longest_orfs.pep | grep ">" | sed 's/:/\t/g' | awk '{print $2}' | sort | uniq > for_annotation

# perl -ne 'if(/^>(\S+)/){$c=$i{$1}}$c?print:chomp;$i{$_}=1 if @ARGV' /Network/Servers/avalanche.plb.ucdavis.edu/Volumes/Mammoth/Users/ruijuanli/assembly_parent/transdecoder/after_cap3/Ol.u.fa.cap.contigs_singlets.transdecoder_dir/for_annotation_ID Ol.u.fa.cap.contigs_singlets > Ol_ref_for_annotation.fa  


```

#### de-novo based 
```{r}
# 1) trim each lib 

# 2) combine trimmed data for Da-Ae & Da-Ol-1 

# 3) run trinity on Da-Ae & Da-Ol-1: stats, N50, how many transcripts? ... length distribution?  
# Da-Ae: genes: 177731; transcripts: 476452; N50_all contigs: 761; 
# Da-Ol-1:  genes: 187252; transcripts: 497089; N50_all contigs: 775;

# 4) get read count for transcripts of Da-Ae & Da-Ol-1, remove transcripts with reads number less than 1: stats? how many transcripts left? length distribution  
# Da-Ae: genes: 50120; transcripts: 102127
# Da-Ol-1: genes: 47464; transcripts: 93678

# 5) predict ORF from transcript dataset using transdecoder: stats, how many transcripts? 
# 75662 for Da-Ae; 69906 for Da-Ol-1 

# 6) blast against B.rapa CDS to extract novel transcript not present in the existing B.rapa genome annotation 
# Da-Ae: 73346 with B.rapa CDS hit (e-value < 1e-6); 67894 above 95% percent identity, so (75662-67894) 7,768 novel genes 
# Da-Ol-1: 67883 with B.rapa CDS hit (e-value < 1e-6); 62905 above 95% percent identity, so (69906-62905) 7,001 novel genes 

# 7) BWA-MEM 7768 Ae genes and 7001 Ol genes to B.napus genome to see how many of them hit B.napus genome 

## unmapped: 3rd column is "*"
# cat Ae_bwa_mem.sam | awk 'NF > 8{print $3}' | sort | uniq -c # 139 unmapped 
# cat Ol_bwa_mem.sam | awk 'NF > 8{print $3}' | sort | uniq -c # 90 unmapped 

# uniquely mapped: absence of "XA:Z" means unqiue mapping 
# cat Ae_bwa_mem.sam | awk 'NF > 8' | grep -v "XA:Z" | awk '{print $1}' | sort | uniq | wc -l 4728
# cat Ol_bwa_mem.sam | awk 'NF > 8' | grep -v "XA:Z" | awk '{print $1}' | sort | uniq | wc -l 4118

# Da-Ae: 4728 genes are uniquely mapped to B.napus genome; 
# Da-Ol-1: 4118 genes are uniquely mapped to B.napus genome; 

# 8) blastx against Uniref protein database (on whitney)
# Da-Ae: 4076 blastx against 3690 Uniref protein (for unknown reason, not every Uniref protein has annotation here using batch entrez, but the ones that are proved to be plant genes are 2873, 10 non-plant genes)
# Da-Ol: 3775 blastx against 3444 Uniref protein (2628 plant genes, and 15 non-plant genes)

# 9) tag uniquely mapped & uniquely mapped genes, blastx unmapped genes to NCBI nr database to see whether they hit plant proteins 
# 39 genes out 139 genes of Da-Ae are found to have blast hit in plant 
# 24 (-1) genes out of 90 genes of Da-Ol-1 are found to have blast hit in plant 

# 10) remove chimera RNA: chimera RNAs are composed of exons from two or more different genes and the potential to encode novel proteins. While natual chimeric transcripts exist in some cancer tissues but are very rare, and most of the cases they are resulted from mis-assembly in transcriptome assembly. So they need to be removed...    

# 11) combine ref based & de-novo assembly 
# Da-Ae 6065+2320
# Da-Ol-1 5548+2427

# 12) after CAP3
# Da-Ae: 6622
# Da-Ol-1: 6430 

# 13) dammit for annotation 

```

# filtering based on ID
```{r}
library(tidyverse)
Ae_unmapped.cds_ID <- read.table(file = "~/assembly_parent/De_novo/filtering/Ae_unmapped.cds_ID")

Ae_unmapped.cds_ID %>% head()
Ae_unmapped.blastx.trinity <- read.csv("~/assembly_parent/De_novo/filtering/Ae_unmapped.blastx.trinity2")


```

#### used for chimera
* get size info for all transcript, used in chimera remove in Uchime 

# structure annotation (possible tool: maker2)
```{r}

```

# functional annotation (possible tool: Blast2GO)
```{r}

```

### figure for length distribution of novel assembly
```{r}
Ae_ref <- read.table("~/Desktop/Brassica_project/KIAT_RNA_seq/assembly/Ae_ref_plain.fa.length", header = F)

Ol_ref <- read.table("~/Desktop/Brassica_project/KIAT_RNA_seq/assembly/Ol_ref_plain.fa.length", header = F)

Ae_denovo <- read.table("~/Desktop/Brassica_project/KIAT_RNA_seq/assembly/Ae_denovo_plain.fa.length", header = F)

Ol_denovo <- read.table("~/Desktop/Brassica_project/KIAT_RNA_seq/assembly/Ol_denovo_plain.fa.length", header = F)

ref_CDS <- read.table("~/Desktop/Brassica_project/KIAT_RNA_seq/assembly/Brassica_napus_length.txt", header = F)

length.distr<- rbind(length.distr.calc(Ae_ref), length.distr.calc(Ol_ref), length.distr.calc(Ae_denovo), length.distr.calc(Ol_denovo), length.distr.calc(ref_CDS))

length.distr$range <- factor(length.distr$range, levels = c("<200","200-500","500-1000","1000-1500","1500-2000","2000-5000",">5000"))
  
# plot 
library(ggplot2)
p.length.distr <- ggplot(data = length.distr)
p.length.distr <- p.length.distr + geom_bar(aes(x=as.factor(range), y=percentage, fill=class), stat = "identity")
p.length.distr <- p.length.distr + facet_wrap(~class) 
p.length.distr <- p.length.distr + labs(list(title = "", x = "length range", y = "percentage"))
p.length.distr <- p.length.distr + theme(axis.text.x = element_text(angle = 90, size = 8))
p.length.distr 
```

### appendix function 
```{r}
length.distr.calc <- function(length.data){
  length.distr <- data.frame(range = c("<200","200-500","500-1000","1000-1500","1500-2000","2000-5000",">5000"), 
                             percentage = c(round(sum(length.data$V2<200)/nrow(length.data), digits = 2), round(sum(length.data$V2>=200 & length.data$V2<500)/nrow(length.data), digits = 2), round(sum(length.data$V2>=500 & length.data$V2<1000)/nrow(length.data), digits = 2),  round(sum(length.data$V2>=1000 & length.data$V2<1500)/nrow(length.data), digits = 2), round(sum(length.data$V2>=1500 & length.data$V2<2000)/nrow(length.data), digits = 2), round(sum(length.data$V2>=2000 & length.data$V2<5000)/nrow(length.data), digits = 2), round(sum(length.data$V2>=5000)/nrow(length.data), digits = 2)),
                          class = deparse(substitute(length.data)))
return(length.distr)
}
```

# Go enrichment for Arabidopsis 
```{r}
# ORA with GOseq
# prerequisit
library(ShortRead);library(goseq);library(GO.db);library("org.At.tair.db");library("annotate")

#TIR10_cdna_rep_model<-readDNAStringSet("../../Nozue2016_SAStranscriptome_data/input/TAIR10_cdna_20110103_representative_gene_model") 
#setwd("../")
TIR10_cdna_rep_model<-readDNAStringSet(file.path(homedir,"..","..","Nozue2016_SAStranscriptome_data/input/TAIR10_cdna_20110103_representative_gene_model") ) ### update this reference gene list 
#setwd(homedir2)
head(TIR10_cdna_rep_model)
bias<-nchar(TIR10_cdna_rep_model)
names(bias)<-substr(names(TIR10_cdna_rep_model),1,9)
length(bias) 
#  bias.data vector must have the same length as DEgenes vector!
###Read in AtGO
Atgo <- toTable(org.At.tairGO)
#head(Atgo)
BP <- TRUE #only keep BP go TERMS
if (BP) Atgo <- Atgo[Atgo$Ontology=="BP",]
#convert to list
Atgo.list <- tapply(Atgo$go_id,Atgo$gene_id,c)

GOseq.ORA<-function(genelist,padjust=0.05) { # return GO enrichment table, padjus, padjust=0.05 , modified 092817
  TF<-(names(bias) %in% genelist)*1
  names(TF)<-names(bias)
  #print(TF)
  pwf<-nullp(TF,bias.data=bias)
  #print(pwf$DEgenes)
  ###Read in AtGO
  Atgo <- toTable(org.At.tairGO)
  #head(Atgo)
  BP <- TRUE #only keep BP go TERMS
  if (BP) Atgo <- Atgo[Atgo$Ontology=="BP",]
  #convert to list
  Atgo.list <- tapply(Atgo$go_id,Atgo$gene_id,c)
  #
  GO.pval <- goseq(pwf,gene2cat=Atgo.list,use_genes_without_cat=TRUE) # format became different in new goseq version (021111)
  #head(GO.pval) 
  GO.pval$over_represented_padjust<-p.adjust(GO.pval$over_represented_pvalue,method="BH")
  #if(GO.pval$over_represented_padjust[1]>padjust) stop("no enriched GO")
  if(GO.pval$over_represented_padjust[1]>padjust) return("no enriched GO")
  
  else {
    enriched.GO<-GO.pval[GO.pval$over_represented_padjust<padjust,] 
    print("enriched.GO is")
    print(enriched.GO)
    
    ## write Term and Definition 
    for(i in 1:dim(enriched.GO)[1]) {
      enriched.GO$Term[i]<-Term(GOTERM[[enriched.GO[i,"category"]]])
      enriched.GO$Definition[i]<-Definition(GOTERM[[enriched.GO[i,"category"]]])
    }
    return(enriched.GO)
  }
}
# example
#enriched.GO.Col.SOMcluster1<-GOseq.ORA(rownames(data.val3.4.SOM.Col.SOM1.all.barcode.s)[rownames(data.val3.4.SOM.Col.SOM1.all.barcode.s) %in% names(bias)]) 
```

