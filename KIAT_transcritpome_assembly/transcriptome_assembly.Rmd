---
title: "Transcritpome_assembly"
author: "Ruijuan Li"
date: "6/26/2017"
output: 
  html_document: 
    keep_md: yes
---

* download data & trimming 
```{r}
# 1) download raw fastq data using wget 

# 2) check data quality using fastqc 

# 3) Trimm off low quality reads & adapter contamination 
# trimmomatic PE Sample_${sample}/${sample}_1.fq.gz Sample_${sample}/${sample}_2.fq.gz Sample_${sample}/${sample}_paired_1.fq.gz Sample_${sample}/${sample}_unpaired_1.fq.gz Sample_${sample}/${sample}_paired_2.fq.gz Sample_${sample}/${sample}_unpaired_2.fq.gz ILLUMINACLIP:Bradseq_adapter.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36

# 4) map high quality reads to reference genome using STAR
# 4.1) add "gene_id" colomn to gff3 file 
# run with modified gff3 file 
# STAR --runMode genomeGenerate --genomeDir star_genome/ --genomeFastaFiles Brassica_napus_v4.1.chromosomes.fa --sjdbGTFfile Brassica_napus.annotation_v5_modified_modified.gff3 --runThreadN 6 --sjdbGTFtagExonParentTranscript Parent --sjdbGTFfeatureExon CDS (screen -r 10070.ttys003.coloma) 

# 4.2)  mapping 
# "STAR --genomeDir /Network/Servers/avalanche.plb.ucdavis.edu/Volumes/Mammoth/Users/ruijuanli/Reference/B.napus/star_genome --readFilesIn /Network/Servers/avalanche.plb.ucdavis.edu/Volumes/Mammoth/Users/ruijuanli/2016_summer/raw_data/Ae_Hu_2_1.fq /Network/Servers/avalanche.plb.ucdavis.edu/Volumes/Mammoth/Users/ruijuanli/2016_summer/raw_data/Ae_Hu_2_2.fq --outSAMtype BAM SortedByCoordinate --sjdbGTFfile /Network/Servers/avalanche.plb.ucdavis.edu/Volumes/Mammoth/Users/ruijuanli/Reference/B.napus/Brassica_napus.annotation_v5_modified_modified.gff3 --quantMode TranscriptomeSAM GeneCounts --twopassMode Basic â€“alignIntronMax 15000 --outFilterIntronMotifs RemoveNoncanonical --runThreadN 6 --sjdbGTFtagExonParentTranscript Parent --sjdbGTFfeatureExon CDS --outReadsUnmapped Fastx" 

# 5) assembly 
# 5.1) use IGV to decide library type 
# after visualize genome, bam file, and gff file, we decide our library type is fr-secondstrand 
# 5.2) assemble each library seperately using cufflinks 
# transcriptome assembly using original gff3 file
# cufflinks  -o /share/malooflab/Ruijuan/parent_assembly/${sample}/cufflink_output/ \
# 	   --junc-alpha 0.001 \
# 	   --label CUFF \
# 	   --max-bundle-length 3500000 \
# 	   --max-intron-length 300000 \
# 	   --max-mle-iterations 5000 \
# 	   --min-frags-per-transfrag 10 \
# 	   --min-intron-length 50 \
# 	   --min-isoform-fraction 0.1 \
# 	   --no-update-check \
# 	   --num-importance-samples 1000 \
# 	   --num-threads 20 \
# 	   --overhang-tolerance 8 \
# 	   --pre-mrna-fraction 0.15 \
# 	   --small-anchor-fraction 0.09 \
# 	   --trim-3-avgcov-thresh 10 \
# 	   --trim-3-dropoff-frac 0.1 \
# 	   --library-type fr-secondstrand \
# 	   -g /share/malooflab/Ruijuan/reference/Brassica_napus.annotation_v5.gff3 \
# 	   -b /home/ruijuanli/2017_winter/assembly/Brassica_napus_v4.1.chromosomes.fa \
# 	    /share/malooflab/Ruijuan/parent_assembly/${sample}/Aligned.sortedByCoord.out.bam

# 6) merge seperate assembly into one using cuffmerge 
# cuffmerge 
# https://github.com/leejimmy93/KIAT_whitney/blob/master/parent_RNA_transcriptome/run_cuffmerge_Ae.sh 

# https://github.com/leejimmy93/KIAT_whitney/blob/master/parent_RNA_transcriptome/run_cuffmerge_Ol.sh

# 7) compare to current annotation for the reference genome  
# cuffcompare 

# https://github.com/leejimmy93/KIAT_whitney/blob/master/parent_RNA_transcriptome/run_cuffcompare_Ae.sh
# https://github.com/leejimmy93/KIAT_whitney/blob/master/parent_RNA_transcriptome/run_cuffcompare_Ol.sh
# get contigs with "u" code, need to remember how I get to here. 

# 8) remove redundant isoforms from novel transcripts using CAP3 
# https://github.com/leejimmy93/KIAT_whitney/blob/master/parent_RNA_transcriptome/run_cap3.sh
# merge contigs & singletons for downstream analysis 

# 9) predict ORF from non-redundant transcript dataset using transdecoder 
# TransDecoder.LongOrfs -t Ae.u.fa.cap.contigs_singlets 
# TransDecoder.LongOrfs -t Ol.u.fa.cap.contigs_singlets 

# blastp against nr protein database to get an idea of what genes they are 
# blastp -query longest_orfs.pep  -db /Network/Servers/avalanche.plb.ucdavis.edu/Volumes/Mammoth/Users/ruijuanli/Reference/NCBI/nr/nr  -max_target_seqs 1 -outfmt 6 -evalue 1e-6 -num_threads 6 -out ${i}_nr.out  

# 10) multiple ORF were produced for each transcript, the number of transcripts with ORF identified are: 
# Da-Ae (2311) & Da-Ol-1 (2427) : cat longest_orfs.pep | grep ">" | sed 's/:/\t/g' | awk '{print $2}' | sort | uniq | wc -l 

# To do: 
# ...11) among the multiple ORFs, which one to use for annotation? Upendra decided to use the one with the max number of significant hits to NCBI nr database. 

# ...12) map transctipts to B.napus genome sequence using BWA-MEM, mapped transcripts VS unmapped transcritps (because these transcritps were assembled from mapped reads, they should still be able to map back the reference genome)

# ...13) convert mapped transcripts (bam/sam format) to bed file using (bamtobed tool)

# ...14) join multiple exons from each transcript in the bed file (custom script)

# ...15) select the best isoform for each transcript based on length, the longest will be retained. (custom script)

# ...16) get fasta file corresponding to the annotation bed file using getfasta utility from BED tools 
```

* Structure Annotation (possible tool: MAKERv2.31.9)
```{r}
# 1) Install and Configure MAKER
# wget http://yandell.topaz.genetics.utah.edu/cgi-bin/maker_license.cgi

# 2) Easy Installation
# tar -xvzf maker-2.31.9.tgz
# In ~/bin/maker/src
# perl Build.PL
# ./Build install
# ./Build installdeps (for missing PERL dependencies, requires root permission)
# ./Build installexes (for missing external programs, requires root permission)

# 3) Separate Directories (for Geno)
# In ~/bin/maker
# mkdir maker.ae
# mkdir maker.ol

# 4) Creating ctl Files
# maker -CTL 
# creates three control files (run this once in maker.ae and maker.ol)
# Edit with Nano (is there a way to automate this?)
# maker_exe.ctl contains path information for executables
# maker_bopts.ctl contains filtering stats for BLAST/Exonerate
# maker_opts.ctl contains location of input genome file

# 5) Configuring ctl Files
# Ae Genotype
# maker_exe.ctl 

# maker_bopts.ctl 

# maker_opts.ctl 
# genome=../../../../ruijuanli/Reference/B.napus/Brassica_napus_v4.1.chromosomes.fa #genome sequence (fasta file or fasta embedded in GFF3 file)
# est=../../../../ruijuanli/assembly_parent/cap3/Ae.u.fa.cap.contigs_singlets
# protein= #prot seq fasta (multiple organisms?)
# protein_gff= #aligned prot homology from external GFF3

# Ol Genotype
# maker_exe.ctl

# maker_bopts.ctl

# maker_opts.ctl
# genome= ../../../../ruijuanli/Reference/B.napus/Brassica_napus_v4.1.chromosomes.fa #genome sequence (fasta file or fasta embedded in GFF3 file)
# est=../../../../ruijuanli/assembly_parent/cap3/Ol.u.fa.cap.contigs_singlets
# protein= #prot seq fasta (multiple organisms?)
# protein_gff= #aligned prot homology from external GFF3

# Command: maker -RM_off|R
# Argument: -RM_off|R turns off all repeat masking options
# Argument: -fix_nucleotides not recognized



# [Detailed Installation Notes]

# Install and Configure Perl
# perl -v to confirm perl is installed (5.8.0+ required)

# perl -MCPAN -e shell to access CPAN shell
# installing modules (may require sudo)
# PERMISSION ISSUES HERE
# install DBI
# install DBD::SQLite
# install Proc::ProcessTable
# install threads
# install IO::All
# install IO::Prompt
# install File::Which
# install Perl::Unsafe::Signals
# install Bit::Vector
# install Inline::C
# install PerlIO::gzip

# Installing Bioperl with CPAN
# perl -MCPAN -e shell
# install Bundle::CPAN
# install Module::Build
# install Bundle::BioPerl

# Installing NCBI-BLAST (Wublast alternative if we have existing copy (no longer freely available))
# Present in server
```

* alternate tool: PASA (2nd option)
```{r}
# install & configure PASA
# wget https://github.com/PASApipeline/PASApipeline/archive/v2.1.0.tar.gz
# tar -xvzf v2.1.0.tar.gz
# go to https://dev.mysql.com/downloads/file/?id=469277 
# dpkg -i mysql-community-client_5.7.18-1ubuntu16.10_amd64.deb "error" 

# PASA pipeline  
#1) seqclean to identify transcript with polyAtail 
# ... 
```

* functional annotation (possible tool: Blast2GO)
```{r}

```


